created: 20200208160214721
modified: 20200208172141170
tags: Python
title: Python Regular Expression Examples
type: text/vnd.tiddlywiki

! Python 正则表达式实例

在本次的实例中会使用下面这个 helper 函数让 match 的结果显示的好看一点：

```python
def displaymatch(match):
    if match is None:
        return None
    return '<Match: %r, groups=%r>' % (match.group(), match.groups())
```

假设你现在在写一个扑克牌程序，玩家的牌被表示为 5 个字符和 2-9 八个数字。

* `a` 代表 ace。
* `2-9` 代表数字
* `t` 代表 10
* `j` 代表 Jack
* `q` 代表 queen
* `k` 代表 king

要检测玩家的五张手牌是否是有效的牌组，可以这样做：

```python
>>> valid = re.compile(r"^[a2-9tjqk]{5}$")
>>> displaymatch(valid.match("akt5q"))  # Valid.
"<Match: 'akt5q', groups=()>"
>>> displaymatch(valid.match("akt5e"))  # Invalid.
>>> displaymatch(valid.match("akt"))    # Invalid.
>>> displaymatch(valid.match("727ak"))  # Valid.
"<Match: '727ak', groups=()>"
```

最后一次匹配的是 `727ak`，包含了一个对子。要使用 RE 匹配对子，可以使用''反引用''：

```python
>>> pair = re.compile(r".*(.).*\1")
>>> displaymatch(pair.match("717ak"))     # Pair of 7s.
"<Match: '717', groups=('7',)>"
>>> displaymatch(pair.match("718ak"))     # No pairs.
>>> displaymatch(pair.match("354aa"))     # Pair of aces.
"<Match: '354aa', groups=('a',)>"
```

要找到成对的牌是哪一个，可以使用 group() 方法。

```python
>>> pair = re.compile(r".*(.).*\1")
>>> pair.match("717ak").group(1)
'7'

# Error because re.match() returns None, which doesn't have a group() method:
>>> pair.match("718ak").group(1)
Traceback (most recent call last):
  File "<pyshell#23>", line 1, in <module>
    re.match(r".*(.).*\1", "718ak").group(1)
AttributeError: 'NoneType' object has no attribute 'group'

>>> pair.match("354aa").group(1)
'a'
```

> 对于上面的例子 `.*(.).*\1` 中使用 `\1` 反引用 `(.)` 中匹配的字符。

!! 模仿 scanf()

Python 没有与 `scanf()` 等价的函数。RE 要比 `scanf()` 更加强大，下表列出了 RE 里与 `scanf()` 里的转义字符大概等价的 Pattern：

|!scanf()|!RE|
|`%c`|`.`|
|`%5c`|`.{5}`|
|`%d`|`[-+]?\d+`|
|`%e`, `%E`, `%f`, `%g`|`[-+]?(\d+(\.\d*)?|\.\d+)([eE][-+]?\d+)?`|
|`%i`|`[-+]?(0[xX][\dA-Fa-f]+|0[0-7]*|\d+)`|
|`%o`|`[-+]?[0-7]+`|
|`%s`|`\S+`|
|`%u`|`\d+`|
|`%x, %X`|`[-+]?(0[xX])?[\dA-Fa-f]+`|

要从下面的字符串中提取出文件名和数字：

```shell
/usr/sbin/sendmail - 0 errors, 4 warnings
```

你可能会使用下面的 scanf 格式：

```bash
%s - %d errors, %d warnings
```

那么等价的 RE 为：

```shell
(\S+) - (\d+) errors, (\d+) warnings
```

!! search() vs. match()

Python 提供了两种基本操作：`re.match()` 仅仅可以匹配字符串的开头。而 `re.search()` 可以匹配字符串的任何位置。

```python
>>> re.match("c", "abcdef")    # No match
>>> re.search("c", "abcdef")   # Match
<re.Match object; span=(2, 3), match='c'>
```

pattern 中可以使用 `^` 来限制匹配字符串的开头，这样 `search()` 就可以和 `match()` 一样了。

> 不同的是，即使使用 `MULTILINE`  标志，`match()` 也仅仅能匹配第一行的开头。而 `^` 可以匹配每一行的开头。


!! 制作电话薄

`split()` 根据给定的 pattern 将字符串分割为 List。这个方法可以将特定格式的文本数据转换为格式化数据，非常有用。

这个例子是根据一些文本生成一个电话薄，下面是原始文本：

```python
>>> text = """Ross McFluff: 834.345.1254 155 Elm Street
...
... Ronald Heathmore: 892.345.3428 436 Finley Avenue
... Frank Burger: 925.541.7625 662 South Dogwood Way
...
...
... Heather Albrecht: 548.326.4584 919 Park Place"""
```

每个样本被一个或多个换行符隔开。首先我们将文本转换为列表，每个 entry 都是一个样本：

```python
>>> entries = re.split("\n+", text)
>>> entries
['Ross McFluff: 834.345.1254 155 Elm Street',
'Ronald Heathmore: 892.345.3428 436 Finley Avenue',
'Frank Burger: 925.541.7625 662 South Dogwood Way',
'Heather Albrecht: 548.326.4584 919 Park Place']
```

然后再将列表内的每一个样本分割为名称，号码和地址：

```python
>>> [re.split(":? ", entry, 3) for entry in entries]
[['Ross', 'McFluff', '834.345.1254', '155 Elm Street'],
['Ronald', 'Heathmore', '892.345.3428', '436 Finley Avenue'],
['Frank', 'Burger', '925.541.7625', '662 South Dogwood Way'],
['Heather', 'Albrecht', '548.326.4584', '919 Park Place']]
```

`:?` pattern 匹配名称后的冒号。如果使用 maxsplit 为 4 的话，可以将房屋号码也分开：

```python
>>> [re.split(":? ", entry, 4) for entry in entries]
[['Ross', 'McFluff', '834.345.1254', '155', 'Elm Street'],
['Ronald', 'Heathmore', '892.345.3428', '436', 'Finley Avenue'],
['Frank', 'Burger', '925.541.7625', '662', 'South Dogwood Way'],
['Heather', 'Albrecht', '548.326.4584', '919', 'Park Place']]
```

!! 文本 Munging

`sub()` 可以用字符串替换每个 pattern 匹配的字符。 这个例子中实现了一个 `munge()` 函数来将文本替换为 Mungging：

```python
>>> def repl(m):
...     inner_word = list(m.group(2))
...     random.shuffle(inner_word)
...     return m.group(1) + "".join(inner_word) + m.group(3)
>>> text = "Professor Abdolmalek, please report your absences promptly."
>>> re.sub(r"(\w)(\w+)(\w)", repl, text)
'Poefsrosr Aealmlobdk, pslaee reorpt your abnseces plmrptoy.'
>>> re.sub(r"(\w)(\w+)(\w)", repl, text)
'Pofsroser Aodlambelk, plasee reoprt yuor asnebces potlmrpy.'
```

!! 查找所有的副词

`findall()` 会匹配所有的 pattern。例如，如果一个写作者想找到文本中的所有副词，可以使用 `findall()`:

```python
>>> text = "He was carefully disguised but captured quickly by police."
>>> re.findall(r"\w+ly", text)
['carefully', 'quickly']
```

> 如果不仅需要找到副词，还需要副词的位置，可以使用 `finditer()`，它返回的是一个迭代器，迭代器中生成的是 match 对象。


!! 编写一个 分词器

一个 [[tokenizer 或者 scanner|https://en.wikipedia.org/wiki/Lexical_analysis]]可以分析一个字符串并且将字符进行分类。这在通常是编写编译器或者解释器的第一步。

文本的类别使用正则表达式指定。这个技术是将那些组合成一个大的 RE 并循环遍历匹配项：

```python
import collections
import re

Token = collections.namedtuple('Token', ['type', 'value', 'line', 'column'])

def tokenize(code):
    keywords = {'IF', 'THEN', 'ENDIF', 'FOR', 'NEXT', 'GOSUB', 'RETURN'}
    token_specification = [
        ('NUMBER',   r'\d+(\.\d*)?'),  # Integer or decimal number
        ('ASSIGN',   r':='),           # Assignment operator
        ('END',      r';'),            # Statement terminator
        ('ID',       r'[A-Za-z]+'),    # Identifiers
        ('OP',       r'[+\-*/]'),      # Arithmetic operators
        ('NEWLINE',  r'\n'),           # Line endings
        ('SKIP',     r'[ \t]+'),       # Skip over spaces and tabs
        ('MISMATCH', r'.'),            # Any other character
    ]
    tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specification)
    line_num = 1
    line_start = 0
    for mo in re.finditer(tok_regex, code):
        kind = mo.lastgroup
        value = mo.group()
        column = mo.start() - line_start
        if kind == 'NUMBER':
            value = float(value) if '.' in value else int(value)
        elif kind == 'ID' and value in keywords:
            kind = value
        elif kind == 'NEWLINE':
            line_start = mo.end()
            line_num += 1
            continue
        elif kind == 'SKIP':
            continue
        elif kind == 'MISMATCH':
            raise RuntimeError(f'{value!r} unexpected on line {line_num}')
        yield Token(kind, value, line_num, column)

statements = '''
    IF quantity THEN
        total := total + price * quantity;
        tax := price * 0.05;
    ENDIF;
'''

for token in tokenize(statements):
    print(token)
```

匹配的结果如下：

```python
Token(type='IF', value='IF', line=2, column=4)
Token(type='ID', value='quantity', line=2, column=7)
Token(type='THEN', value='THEN', line=2, column=16)
Token(type='ID', value='total', line=3, column=8)
Token(type='ASSIGN', value=':=', line=3, column=14)
Token(type='ID', value='total', line=3, column=17)
Token(type='OP', value='+', line=3, column=23)
Token(type='ID', value='price', line=3, column=25)
Token(type='OP', value='*', line=3, column=31)
Token(type='ID', value='quantity', line=3, column=33)
Token(type='END', value=';', line=3, column=41)
Token(type='ID', value='tax', line=4, column=8)
Token(type='ASSIGN', value=':=', line=4, column=12)
Token(type='ID', value='price', line=4, column=15)
Token(type='OP', value='*', line=4, column=21)
Token(type='NUMBER', value=0.05, line=4, column=23)
Token(type='END', value=';', line=4, column=27)
Token(type='ENDIF', value='ENDIF', line=5, column=4)
Token(type='END', value=';', line=5, column=9)
```

